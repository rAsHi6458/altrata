{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c2c22ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4174 entries, 0 to 4173\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Sex             4174 non-null   object \n",
      " 1   Length          4174 non-null   float64\n",
      " 2   Diameter        4174 non-null   float64\n",
      " 3   Height          4174 non-null   float64\n",
      " 4   Whole_weight    4174 non-null   float64\n",
      " 5   Shucked_weight  4174 non-null   float64\n",
      " 6   Viscera_weight  4174 non-null   float64\n",
      " 7   Shell_weight    4174 non-null   float64\n",
      " 8   Class           4174 non-null   object \n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 293.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "import pandas as pd\n",
    "df = pd.read_csv('unbalanced.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52d98875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Class</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>0.560</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4174 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0      0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1      0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2      0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3      0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4      0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "...      ...       ...     ...           ...             ...             ...   \n",
       "4169   0.560     0.430   0.155        0.8675          0.4000          0.1720   \n",
       "4170   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
       "4171   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
       "4172   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
       "4173   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
       "\n",
       "      Shell_weight  Class  Sex_I  Sex_M  \n",
       "0           0.1500      0      0      1  \n",
       "1           0.0700      0      0      1  \n",
       "2           0.2100      0      0      0  \n",
       "3           0.1550      0      0      1  \n",
       "4           0.0550      0      1      0  \n",
       "...            ...    ...    ...    ...  \n",
       "4169        0.2290      0      0      1  \n",
       "4170        0.2490      0      0      0  \n",
       "4171        0.2605      0      0      1  \n",
       "4172        0.3080      0      0      1  \n",
       "4173        0.2960      0      0      0  \n",
       "\n",
       "[4174 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transforming categorical columns\n",
    "df['Class'] = df['Class'].map(lambda x: 0 if x == 'negative' else 1)\n",
    "df = pd.get_dummies(df, columns=['Sex'], drop_first=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a83dc2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4142\n",
       "1      32\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50d59413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting training and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, stratify=df['Class'], random_state=888)\n",
    "\n",
    "features = df_train.drop(columns=['Class']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3c708a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3313\n",
       "1      26\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Class'].value_counts()\n",
    "df_test['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0885065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3313\n",
       "1    3313\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Oversampling\n",
    "#Simple random oversampling\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=888)\n",
    "X_resampled, y_resampled = ros.fit_resample(df_train[features], df_train['Class'])\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "894e55cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\rathakra2201\\Anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - imbalanced-learn\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _anaconda_depends-2023.03  |           py39_0          66 KB\n",
      "    anaconda-custom            |           py39_1           4 KB\n",
      "    ca-certificates-2023.5.7   |       h56e8100_0         145 KB  conda-forge\n",
      "    certifi-2023.5.7           |     pyhd8ed1ab_0         149 KB  conda-forge\n",
      "    flask-1.1.2                |     pyh9f0ad1d_0          70 KB  conda-forge\n",
      "    huggingface_hub-0.14.1     |     pyhd8ed1ab_0         156 KB  conda-forge\n",
      "    imbalanced-learn-0.10.1    |     pyhd8ed1ab_0         131 KB  conda-forge\n",
      "    jinja2-2.11.3              |     pyhd8ed1ab_2          94 KB  conda-forge\n",
      "    libuv-1.44.2               |       h8ffe710_0         362 KB  conda-forge\n",
      "    markupsafe-1.1.1           |   py39hb82d6ee_4          30 KB  conda-forge\n",
      "    ninja-1.10.2               |       haa95532_5          14 KB\n",
      "    ninja-base-1.10.2          |       h6d14046_5         255 KB\n",
      "    openssl-1.1.1t             |       h2bbff1b_0         5.5 MB\n",
      "    python_abi-3.9             |           2_cp39           4 KB  conda-forge\n",
      "    pytorch-1.12.1             |cpu_py39h5e1f01c_1        80.5 MB\n",
      "    sqlalchemy-1.4.13          |   py39hb82d6ee_0         2.3 MB  conda-forge\n",
      "    tokenizers-0.11.4          |   py39he5181cf_1         2.4 MB\n",
      "    transformers-4.24.0        |   py39haa95532_0         4.7 MB\n",
      "    werkzeug-2.1.2             |     pyhd8ed1ab_1         237 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        97.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _anaconda_depends  pkgs/main/win-64::_anaconda_depends-2023.03-py39_0 None\n",
      "  flask              conda-forge/noarch::flask-1.1.2-pyh9f0ad1d_0 None\n",
      "  huggingface_hub    conda-forge/noarch::huggingface_hub-0.14.1-pyhd8ed1ab_0 None\n",
      "  imbalanced-learn   conda-forge/noarch::imbalanced-learn-0.10.1-pyhd8ed1ab_0 None\n",
      "  jinja2             conda-forge/noarch::jinja2-2.11.3-pyhd8ed1ab_2 None\n",
      "  libuv              conda-forge/win-64::libuv-1.44.2-h8ffe710_0 None\n",
      "  markupsafe         conda-forge/win-64::markupsafe-1.1.1-py39hb82d6ee_4 None\n",
      "  ninja              pkgs/main/win-64::ninja-1.10.2-haa95532_5 None\n",
      "  ninja-base         pkgs/main/win-64::ninja-base-1.10.2-h6d14046_5 None\n",
      "  python_abi         conda-forge/win-64::python_abi-3.9-2_cp39 None\n",
      "  pytorch            pkgs/main/win-64::pytorch-1.12.1-cpu_py39h5e1f01c_1 None\n",
      "  regex              pkgs/main/win-64::regex-2022.7.9-py39h2bbff1b_0 None\n",
      "  sqlalchemy         conda-forge/win-64::sqlalchemy-1.4.13-py39hb82d6ee_0 None\n",
      "  tokenizers         pkgs/main/win-64::tokenizers-0.11.4-py39he5181cf_1 None\n",
      "  transformers       pkgs/main/win-64::transformers-4.24.0-py39haa95532_0 None\n",
      "  werkzeug           conda-forge/noarch::werkzeug-2.1.2-pyhd8ed1ab_1 None\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2022.07.19~ --> conda-forge::ca-certificates-2023.5.7-h56e8100_0 None\n",
      "  certifi            pkgs/main/win-64::certifi-2022.9.14-p~ --> conda-forge/noarch::certifi-2023.5.7-pyhd8ed1ab_0 None\n",
      "  openssl                                 1.1.1q-h2bbff1b_0 --> 1.1.1t-h2bbff1b_0 None\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  anaconda                                   2022.10-py39_0 --> custom-py39_1 None\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "huggingface_hub-0.14 | 156 KB    |            |   0% \n",
      "huggingface_hub-0.14 | 156 KB    | #          |  10% \n",
      "huggingface_hub-0.14 | 156 KB    | ####       |  41% \n",
      "huggingface_hub-0.14 | 156 KB    | ########## | 100% \n",
      "huggingface_hub-0.14 | 156 KB    | ########## | 100% \n",
      "\n",
      "transformers-4.24.0  | 4.7 MB    |            |   0% \n",
      "transformers-4.24.0  | 4.7 MB    |            |   0% \n",
      "transformers-4.24.0  | 4.7 MB    | #5         |  16% \n",
      "transformers-4.24.0  | 4.7 MB    | ###8       |  39% \n",
      "transformers-4.24.0  | 4.7 MB    | #####3     |  53% \n",
      "transformers-4.24.0  | 4.7 MB    | ########4  |  85% \n",
      "transformers-4.24.0  | 4.7 MB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2023 | 145 KB    |            |   0% \n",
      "ca-certificates-2023 | 145 KB    | ########## | 100% \n",
      "ca-certificates-2023 | 145 KB    | ########## | 100% \n",
      "\n",
      "certifi-2023.5.7     | 149 KB    |            |   0% \n",
      "certifi-2023.5.7     | 149 KB    | #          |  11% \n",
      "certifi-2023.5.7     | 149 KB    | ########## | 100% \n",
      "certifi-2023.5.7     | 149 KB    | ########## | 100% \n",
      "\n",
      "sqlalchemy-1.4.13    | 2.3 MB    |            |   0% \n",
      "sqlalchemy-1.4.13    | 2.3 MB    |            |   1% \n",
      "sqlalchemy-1.4.13    | 2.3 MB    | #2         |  12% \n",
      "sqlalchemy-1.4.13    | 2.3 MB    | ##3        |  24% \n",
      "sqlalchemy-1.4.13    | 2.3 MB    | ###6       |  36% \n",
      "sqlalchemy-1.4.13    | 2.3 MB    | ####8      |  49% \n",
      "sqlalchemy-1.4.13    | 2.3 MB    | ######3    |  64% \n",
      "sqlalchemy-1.4.13    | 2.3 MB    | ########8  |  89% \n",
      "sqlalchemy-1.4.13    | 2.3 MB    | ########## | 100% \n",
      "\n",
      "markupsafe-1.1.1     | 30 KB     |            |   0% \n",
      "markupsafe-1.1.1     | 30 KB     | #####3     |  53% \n",
      "markupsafe-1.1.1     | 30 KB     | ########## | 100% \n",
      "\n",
      "_anaconda_depends-20 | 66 KB     |            |   0% \n",
      "_anaconda_depends-20 | 66 KB     | ########## | 100% \n",
      "_anaconda_depends-20 | 66 KB     | ########## | 100% \n",
      "\n",
      "ninja-1.10.2         | 14 KB     |            |   0% \n",
      "ninja-1.10.2         | 14 KB     | ########## | 100% \n",
      "ninja-1.10.2         | 14 KB     | ########## | 100% \n",
      "\n",
      "ninja-base-1.10.2    | 255 KB    |            |   0% \n",
      "ninja-base-1.10.2    | 255 KB    | ########## | 100% \n",
      "ninja-base-1.10.2    | 255 KB    | ########## | 100% \n",
      "\n",
      "werkzeug-2.1.2       | 237 KB    |            |   0% \n",
      "werkzeug-2.1.2       | 237 KB    | ########## | 100% \n",
      "werkzeug-2.1.2       | 237 KB    | ########## | 100% \n",
      "\n",
      "pytorch-1.12.1       | 80.5 MB   |            |   0% \n",
      "pytorch-1.12.1       | 80.5 MB   |            |   0% \n",
      "pytorch-1.12.1       | 80.5 MB   | 1          |   1% \n",
      "pytorch-1.12.1       | 80.5 MB   | 1          |   2% \n",
      "pytorch-1.12.1       | 80.5 MB   | 2          |   3% \n",
      "pytorch-1.12.1       | 80.5 MB   | 3          |   4% \n",
      "pytorch-1.12.1       | 80.5 MB   | 4          |   4% \n",
      "pytorch-1.12.1       | 80.5 MB   | 5          |   5% \n",
      "pytorch-1.12.1       | 80.5 MB   | 6          |   6% \n",
      "pytorch-1.12.1       | 80.5 MB   | 7          |   7% \n",
      "pytorch-1.12.1       | 80.5 MB   | 8          |   9% \n",
      "pytorch-1.12.1       | 80.5 MB   | 9          |   9% \n",
      "pytorch-1.12.1       | 80.5 MB   | #          |  10% \n",
      "pytorch-1.12.1       | 80.5 MB   | #1         |  11% \n",
      "pytorch-1.12.1       | 80.5 MB   | #2         |  12% \n",
      "pytorch-1.12.1       | 80.5 MB   | #3         |  13% \n",
      "pytorch-1.12.1       | 80.5 MB   | #3         |  14% \n",
      "pytorch-1.12.1       | 80.5 MB   | #4         |  15% \n",
      "pytorch-1.12.1       | 80.5 MB   | #5         |  15% \n",
      "pytorch-1.12.1       | 80.5 MB   | #6         |  16% \n",
      "pytorch-1.12.1       | 80.5 MB   | #6         |  17% \n",
      "pytorch-1.12.1       | 80.5 MB   | #7         |  18% \n",
      "pytorch-1.12.1       | 80.5 MB   | #8         |  19% \n",
      "pytorch-1.12.1       | 80.5 MB   | #9         |  19% \n",
      "pytorch-1.12.1       | 80.5 MB   | ##         |  20% \n",
      "pytorch-1.12.1       | 80.5 MB   | ##1        |  21% \n",
      "pytorch-1.12.1       | 80.5 MB   | ##2        |  23% \n",
      "pytorch-1.12.1       | 80.5 MB   | ##3        |  24% \n",
      "pytorch-1.12.1       | 80.5 MB   | ##4        |  24% \n",
      "pytorch-1.12.1       | 80.5 MB   | ##5        |  25% \n",
      "pytorch-1.12.1       | 80.5 MB   | ##5        |  26% \n",
      "pytorch-1.12.1       | 80.5 MB   | ##6        |  27% \n",
      "pytorch-1.12.1       | 80.5 MB   | ##7        |  27% \n",
      "pytorch-1.12.1       | 80.5 MB   | ##8        |  28% \n",
      "pytorch-1.12.1       | 80.5 MB   | ##8        |  29% \n",
      "pytorch-1.12.1       | 80.5 MB   | ##9        |  30% \n",
      "pytorch-1.12.1       | 80.5 MB   | ###        |  31% \n",
      "pytorch-1.12.1       | 80.5 MB   | ###1       |  32% \n",
      "pytorch-1.12.1       | 80.5 MB   | ###2       |  33% \n",
      "pytorch-1.12.1       | 80.5 MB   | ###3       |  34% \n",
      "pytorch-1.12.1       | 80.5 MB   | ###4       |  35% \n",
      "pytorch-1.12.1       | 80.5 MB   | ###5       |  35% \n",
      "pytorch-1.12.1       | 80.5 MB   | ###6       |  36% \n",
      "pytorch-1.12.1       | 80.5 MB   | ###6       |  37% \n",
      "pytorch-1.12.1       | 80.5 MB   | ###7       |  38% \n",
      "pytorch-1.12.1       | 80.5 MB   | ###8       |  38% \n",
      "pytorch-1.12.1       | 80.5 MB   | ###9       |  39% \n",
      "pytorch-1.12.1       | 80.5 MB   | ###9       |  40% \n",
      "pytorch-1.12.1       | 80.5 MB   | ####       |  41% \n",
      "pytorch-1.12.1       | 80.5 MB   | ####1      |  42% \n",
      "pytorch-1.12.1       | 80.5 MB   | ####2      |  42% \n",
      "pytorch-1.12.1       | 80.5 MB   | ####3      |  43% \n",
      "pytorch-1.12.1       | 80.5 MB   | ####4      |  44% \n",
      "pytorch-1.12.1       | 80.5 MB   | ####5      |  45% \n",
      "pytorch-1.12.1       | 80.5 MB   | ####6      |  46% \n",
      "pytorch-1.12.1       | 80.5 MB   | ####6      |  47% \n",
      "pytorch-1.12.1       | 80.5 MB   | ####7      |  48% \n",
      "pytorch-1.12.1       | 80.5 MB   | ####8      |  49% \n",
      "pytorch-1.12.1       | 80.5 MB   | ####9      |  50% \n",
      "pytorch-1.12.1       | 80.5 MB   | #####      |  50% \n",
      "pytorch-1.12.1       | 80.5 MB   | #####1     |  51% \n",
      "pytorch-1.12.1       | 80.5 MB   | #####2     |  52% \n",
      "pytorch-1.12.1       | 80.5 MB   | #####2     |  53% \n",
      "pytorch-1.12.1       | 80.5 MB   | #####3     |  54% \n",
      "pytorch-1.12.1       | 80.5 MB   | #####4     |  54% \n",
      "pytorch-1.12.1       | 80.5 MB   | #####5     |  55% \n",
      "pytorch-1.12.1       | 80.5 MB   | #####6     |  56% \n",
      "pytorch-1.12.1       | 80.5 MB   | #####6     |  57% \n",
      "pytorch-1.12.1       | 80.5 MB   | #####7     |  58% \n",
      "pytorch-1.12.1       | 80.5 MB   | #####8     |  59% \n",
      "pytorch-1.12.1       | 80.5 MB   | #####9     |  60% \n",
      "pytorch-1.12.1       | 80.5 MB   | ######     |  60% \n",
      "pytorch-1.12.1       | 80.5 MB   | ######1    |  61% \n",
      "pytorch-1.12.1       | 80.5 MB   | ######1    |  62% \n",
      "pytorch-1.12.1       | 80.5 MB   | ######2    |  63% \n",
      "pytorch-1.12.1       | 80.5 MB   | ######3    |  63% \n",
      "pytorch-1.12.1       | 80.5 MB   | ######4    |  64% \n",
      "pytorch-1.12.1       | 80.5 MB   | ######5    |  66% \n",
      "pytorch-1.12.1       | 80.5 MB   | ######6    |  67% \n",
      "pytorch-1.12.1       | 80.5 MB   | ######7    |  68% \n",
      "pytorch-1.12.1       | 80.5 MB   | ######9    |  69% \n",
      "pytorch-1.12.1       | 80.5 MB   | #######    |  70% \n",
      "pytorch-1.12.1       | 80.5 MB   | #######    |  71% \n",
      "pytorch-1.12.1       | 80.5 MB   | #######1   |  72% \n",
      "pytorch-1.12.1       | 80.5 MB   | #######2   |  72% \n",
      "pytorch-1.12.1       | 80.5 MB   | #######3   |  73% \n",
      "pytorch-1.12.1       | 80.5 MB   | #######3   |  74% \n",
      "pytorch-1.12.1       | 80.5 MB   | #######4   |  75% \n",
      "pytorch-1.12.1       | 80.5 MB   | #######5   |  75% \n",
      "pytorch-1.12.1       | 80.5 MB   | #######6   |  76% \n",
      "pytorch-1.12.1       | 80.5 MB   | #######6   |  77% \n",
      "pytorch-1.12.1       | 80.5 MB   | #######7   |  78% \n",
      "pytorch-1.12.1       | 80.5 MB   | #######8   |  79% \n",
      "pytorch-1.12.1       | 80.5 MB   | #######9   |  80% \n",
      "pytorch-1.12.1       | 80.5 MB   | ########1  |  81% \n",
      "pytorch-1.12.1       | 80.5 MB   | ########1  |  82% \n",
      "pytorch-1.12.1       | 80.5 MB   | ########2  |  83% \n",
      "pytorch-1.12.1       | 80.5 MB   | ########3  |  84% \n",
      "pytorch-1.12.1       | 80.5 MB   | ########4  |  84% \n",
      "pytorch-1.12.1       | 80.5 MB   | ########5  |  85% \n",
      "pytorch-1.12.1       | 80.5 MB   | ########6  |  86% \n",
      "pytorch-1.12.1       | 80.5 MB   | ########6  |  87% \n",
      "pytorch-1.12.1       | 80.5 MB   | ########7  |  88% \n",
      "pytorch-1.12.1       | 80.5 MB   | ########8  |  89% \n",
      "pytorch-1.12.1       | 80.5 MB   | ########9  |  89% \n",
      "pytorch-1.12.1       | 80.5 MB   | #########  |  90% \n",
      "pytorch-1.12.1       | 80.5 MB   | #########1 |  91% \n",
      "pytorch-1.12.1       | 80.5 MB   | #########1 |  92% \n",
      "pytorch-1.12.1       | 80.5 MB   | #########2 |  93% \n",
      "pytorch-1.12.1       | 80.5 MB   | #########3 |  94% \n",
      "pytorch-1.12.1       | 80.5 MB   | #########4 |  95% \n",
      "pytorch-1.12.1       | 80.5 MB   | #########5 |  95% \n",
      "pytorch-1.12.1       | 80.5 MB   | #########6 |  96% \n",
      "pytorch-1.12.1       | 80.5 MB   | #########6 |  97% \n",
      "pytorch-1.12.1       | 80.5 MB   | #########7 |  98% \n",
      "pytorch-1.12.1       | 80.5 MB   | #########8 |  99% \n",
      "pytorch-1.12.1       | 80.5 MB   | #########9 |  99% \n",
      "pytorch-1.12.1       | 80.5 MB   | ########## | 100% \n",
      "pytorch-1.12.1       | 80.5 MB   | ########## | 100% \n",
      "\n",
      "libuv-1.44.2         | 362 KB    |            |   0% \n",
      "libuv-1.44.2         | 362 KB    | 4          |   4% \n",
      "libuv-1.44.2         | 362 KB    | ########## | 100% \n",
      "libuv-1.44.2         | 362 KB    | ########## | 100% \n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "anaconda-custom      | 4 KB      |            |   0% \n",
      "anaconda-custom      | 4 KB      | ########## | 100% \n",
      "anaconda-custom      | 4 KB      | ########## | 100% \n",
      "\n",
      "imbalanced-learn-0.1 | 131 KB    |            |   0% \n",
      "imbalanced-learn-0.1 | 131 KB    | #2         |  12% \n",
      "imbalanced-learn-0.1 | 131 KB    | ########## | 100% \n",
      "imbalanced-learn-0.1 | 131 KB    | ########## | 100% \n",
      "\n",
      "python_abi-3.9       | 4 KB      |            |   0% \n",
      "python_abi-3.9       | 4 KB      | ########## | 100% \n",
      "python_abi-3.9       | 4 KB      | ########## | 100% \n",
      "\n",
      "tokenizers-0.11.4    | 2.4 MB    |            |   0% \n",
      "tokenizers-0.11.4    | 2.4 MB    | #6         |  17% \n",
      "tokenizers-0.11.4    | 2.4 MB    | ####7      |  47% \n",
      "tokenizers-0.11.4    | 2.4 MB    | ########3  |  83% \n",
      "tokenizers-0.11.4    | 2.4 MB    | ########## | 100% \n",
      "\n",
      "openssl-1.1.1t       | 5.5 MB    |            |   0% \n",
      "openssl-1.1.1t       | 5.5 MB    | #3         |  13% \n",
      "openssl-1.1.1t       | 5.5 MB    | ###5       |  36% \n",
      "openssl-1.1.1t       | 5.5 MB    | #####2     |  53% \n",
      "openssl-1.1.1t       | 5.5 MB    | #######8   |  79% \n",
      "openssl-1.1.1t       | 5.5 MB    | #########5 |  95% \n",
      "openssl-1.1.1t       | 5.5 MB    | ########## | 100% \n",
      "\n",
      "flask-1.1.2          | 70 KB     |            |   0% \n",
      "flask-1.1.2          | 70 KB     | ########## | 100% \n",
      "flask-1.1.2          | 70 KB     | ########## | 100% \n",
      "\n",
      "jinja2-2.11.3        | 94 KB     |            |   0% \n",
      "jinja2-2.11.3        | 94 KB     | ########## | 100% \n",
      "jinja2-2.11.3        | 94 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Retrieving notices: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/win-64::anaconda==2022.10=py39_0\n",
      "  - defaults/win-64::anaconda-project==0.11.1=py39haa95532_0\n",
      "  - defaults/win-64::bokeh==2.4.3=py39haa95532_0\n",
      "  - defaults/win-64::conda-build==3.22.0=py39haa95532_0\n",
      "  - defaults/noarch::conda-verify==3.4.2=py_1\n",
      "  - defaults/noarch::cookiecutter==1.7.3=pyhd3eb1b0_0\n",
      "  - defaults/win-64::dask==2022.7.0=py39haa95532_0\n",
      "  - defaults/win-64::datashader==0.14.1=py39haa95532_0\n",
      "  - defaults/win-64::distributed==2022.7.0=py39haa95532_0\n",
      "  - defaults/win-64::holoviews==1.15.0=py39haa95532_0\n",
      "  - defaults/win-64::hvplot==0.8.0=py39haa95532_0\n",
      "  - defaults/noarch::intake==0.6.5=pyhd3eb1b0_0\n",
      "  - defaults/noarch::ipywidgets==7.6.5=pyhd3eb1b0_1\n",
      "  - defaults/noarch::jinja2-time==0.2.0=pyhd3eb1b0_3\n",
      "  - defaults/win-64::jupyter==1.0.0=py39haa95532_8\n",
      "  - defaults/win-64::jupyterlab==3.4.4=py39haa95532_0\n",
      "  - defaults/noarch::jupyterlab_server==2.10.3=pyhd3eb1b0_1\n",
      "  - defaults/win-64::jupyter_server==1.18.1=py39haa95532_0\n",
      "  - defaults/noarch::nbclassic==0.3.5=pyhd3eb1b0_0\n",
      "  - defaults/win-64::nbconvert==6.4.4=py39haa95532_0\n",
      "  - defaults/noarch::nltk==3.7=pyhd3eb1b0_0\n",
      "  - defaults/win-64::notebook==6.4.12=py39haa95532_0\n",
      "  - defaults/win-64::numpydoc==1.4.0=py39haa95532_0\n",
      "  - defaults/win-64::panel==0.13.1=py39haa95532_0\n",
      "  - defaults/win-64::sphinx==5.0.2=py39haa95532_0\n",
      "  - defaults/win-64::spyder==5.2.2=py39haa95532_1\n",
      "  - defaults/win-64::widgetsnbextension==3.5.2=py39haa95532_0\n",
      "  - defaults/win-64::_ipyw_jlab_nb_ext_conf==0.1.0=py39haa95532_0\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deae8684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.838962605548854"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=888)\n",
    "\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "y_pred = clf.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(df_test['Class'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23b9469c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3313\n",
       "1    3313\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Oversampling with shrinkage\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=888, shrinkage=0.1)\n",
    "X_resampled, y_resampled = ros.fit_resample(df_train[features], df_train['Class'])\n",
    "\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c9978f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8059911540008041"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=888)\n",
    "\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "y_pred = clf.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(df_test['Class'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f38da00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3313\n",
       "1    3313\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Oversampling using SMOTE (Synthetic Minority Over-sampling TEchnique)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=888)\n",
    "X_resampled, y_resampled = smote.fit_resample(df_train[features], df_train['Class'])\n",
    "\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0bbaff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7913148371531966"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=888)\n",
    "\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "y_pred = clf.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(df_test['Class'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01ccf021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    26\n",
       "1    26\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Undersampling\n",
    "#Simple random undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=888)\n",
    "X_resampled, y_resampled = rus.fit_resample(df_train[features], df_train['Class'])\n",
    "\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f04dfa54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6465621230398071"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=888)\n",
    "\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "y_pred = clf.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(df_test['Class'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82e8ba10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    26\n",
       "1    26\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Undersampling using K-Means/Cluster Centroids\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "cc = ClusterCentroids(random_state=888)\n",
    "X_resampled, y_resampled = cc.fit_resample(df_train[features], df_train['Class'])\n",
    "\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a49622c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6174105347808605"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=888)\n",
    "\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "y_pred = clf.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(df_test['Class'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edd1cc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3298\n",
       "1      26\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Undersampling using Tomek links\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tl = TomekLinks()\n",
    "X_resampled, y_resampled = tl.fit_resample(df_train[features], df_train['Class'])\n",
    "\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe69e435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.683956574185766"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=888)\n",
    "\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "y_pred = clf.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(df_test['Class'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbfd45aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3309\n",
       "1    3309\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combining Oversampling and Undersampling\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smote_tomek = SMOTETomek(random_state=888)\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(df_train[features], df_train['Class'])\n",
    "\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6914fa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7913148371531966"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=888)\n",
    "\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "y_pred = clf.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(df_test['Class'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b4949b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50392394, 64.21153846])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weighing classes differently\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "weights = compute_class_weight('balanced', classes=df_train['Class'].unique(), y=df_train['Class'])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e961aa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1669.5\n",
      "1669.5000000000002\n"
     ]
    }
   ],
   "source": [
    "print((df_train['Class'] == 0).sum()*weights[0])\n",
    "\n",
    "print((df_train['Class'] == 1).sum()*weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fe90dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339.0\n",
      "3339\n"
     ]
    }
   ],
   "source": [
    "print((df_train['Class'] == 0).sum()*weights[0] + (df_train['Class'] == 1).sum()*weights[1])\n",
    "\n",
    "print((df_train['Class'] == 0).sum() + (df_train['Class'] == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a82934e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8275030156815439"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_weighted = LogisticRegression(class_weight='balanced', random_state=888)\n",
    "clf_weighted.fit(df_train[features], df_train['Class'])\n",
    "\n",
    "y_pred = clf_weighted.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(df_test['Class'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46a7df54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8375552874949739"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_weighted = LogisticRegression(class_weight={0: 1, 1: 100}, random_state=888)\n",
    "\n",
    "clf_weighted.fit(df_train[features], df_train['Class'])\n",
    "y_pred = clf_weighted.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(df_test['Class'], y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
